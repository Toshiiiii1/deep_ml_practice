## [Implement Precision Metric](https://www.deep-ml.com/problems/46) ![Difficulty](https://img.shields.io/badge/-Easy-brightgreen)

Write a Python function precision that calculates the precision metric given two numpy arrays: y_true and y_pred. The y_true array contains the true binary labels, and the y_pred array contains the predicted binary labels. Precision is defined as the ratio of true positives to the sum of true positives and false positives.

### Example:

**Input:**

```
y_true = np.array([1, 0, 1, 1, 0, 1])
y_pred = np.array([1, 0, 1, 0, 0, 1])

result = precision(y_true, y_pred)
print(result)
```


**Output:**

```1.0```
